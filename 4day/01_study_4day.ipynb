{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_iris()[\"data\"]\n",
    "y = load_iris()[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    c = np.max(x)\n",
    "    x = x-c\n",
    "    return np.exp(x)/np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def softmax(a):\n",
    "#     exp_a = np.exp(a)\n",
    "#     sum_exp_a = np.sum(exp_a)\n",
    "#     y = exp_a / sum_exp_a\n",
    "    \n",
    "#     return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.sum(softmax(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_crossentropy(t,y):\n",
    "    return np.mean(-t*np.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_one(x):\n",
    "#     result = np.zeros((x.size, np.unique(x).size))\n",
    "#     for idx, val in enumerate(x):\n",
    "#         result[idx][val] = 1\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one(x):\n",
    "    result = np.zeros((x.size, np.unique(x).size))\n",
    "    for idx1,idx2 in enumerate(x):\n",
    "        result[idx1,idx2] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = make_one(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]\n",
    "output_shape = y.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(4,50)\n",
    "b1 = np.zeros(50)\n",
    "W2 = np.random.randn(50,3)\n",
    "b2 = np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    W1 = np.random.randn(4,50)\n",
    "    b1 = np.zeros(50)\n",
    "    W2 = np.random.randn(50,3)\n",
    "    b2 = np.zeros(3)\n",
    "    layer1 = np.dot(x,W1) + b1\n",
    "    z1 = sigmoid(layer1)\n",
    "    layer2 = np.dot(z1,W2) + b2\n",
    "    out = softmax(layer2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.45210875e-05, 6.42060936e-03, 2.49654904e-06],\n",
       "       [1.33967268e-05, 7.34885636e-03, 1.97171722e-06],\n",
       "       [1.41248920e-05, 6.35091740e-03, 2.56029988e-06],\n",
       "       [1.36897624e-05, 6.94310606e-03, 2.26066506e-06],\n",
       "       [1.48413108e-05, 6.08359958e-03, 2.77390808e-06],\n",
       "       [1.25757260e-05, 6.44258305e-03, 1.93102571e-06],\n",
       "       [1.33453811e-05, 5.86791245e-03, 2.54988485e-06],\n",
       "       [1.41544911e-05, 6.75304781e-03, 2.30702446e-06],\n",
       "       [1.34881781e-05, 6.89155956e-03, 2.29549114e-06],\n",
       "       [1.48150477e-05, 7.49133601e-03, 2.26323634e-06],\n",
       "       [1.46782635e-05, 6.58033793e-03, 2.38554234e-06],\n",
       "       [1.40818532e-05, 6.82756588e-03, 2.35766530e-06],\n",
       "       [1.47820044e-05, 7.39768230e-03, 2.32732863e-06],\n",
       "       [1.51561742e-05, 5.95249572e-03, 3.35577062e-06],\n",
       "       [1.58516175e-05, 5.85113917e-03, 2.97102778e-06],\n",
       "       [1.43795537e-05, 5.37357118e-03, 2.75171072e-06],\n",
       "       [1.33927447e-05, 5.48865363e-03, 2.48001814e-06],\n",
       "       [1.33385685e-05, 6.27864772e-03, 2.22689373e-06],\n",
       "       [1.30795966e-05, 6.99013427e-03, 1.81763738e-06],\n",
       "       [1.39863507e-05, 5.92892379e-03, 2.55586472e-06],\n",
       "       [1.34763459e-05, 7.60009089e-03, 1.79334434e-06],\n",
       "       [1.26445984e-05, 5.97851934e-03, 2.14423182e-06],\n",
       "       [1.54253882e-05, 4.56424178e-03, 4.21930015e-06],\n",
       "       [1.05760923e-05, 7.01449777e-03, 1.37903957e-06],\n",
       "       [1.35566517e-05, 7.80484741e-03, 2.02039453e-06],\n",
       "       [1.31156108e-05, 7.82375382e-03, 1.74643168e-06],\n",
       "       [1.18101125e-05, 6.66998813e-03, 1.74794361e-06],\n",
       "       [1.42730912e-05, 6.76759784e-03, 2.26969452e-06],\n",
       "       [1.41658067e-05, 6.78083986e-03, 2.24369800e-06],\n",
       "       [1.37073579e-05, 7.11745847e-03, 2.18820874e-06],\n",
       "       [1.34609835e-05, 7.40473708e-03, 1.99425226e-06],\n",
       "       [1.15720449e-05, 6.95933348e-03, 1.56968699e-06],\n",
       "       [1.69360354e-05, 5.74642621e-03, 3.65659625e-06],\n",
       "       [1.62730509e-05, 5.47529282e-03, 3.39892225e-06],\n",
       "       [1.35171474e-05, 7.28739413e-03, 2.00440216e-06],\n",
       "       [1.40244906e-05, 6.65684522e-03, 2.36272198e-06],\n",
       "       [1.43155650e-05, 6.82221681e-03, 2.22727146e-06],\n",
       "       [1.60584696e-05, 6.11654634e-03, 3.21620935e-06],\n",
       "       [1.37816645e-05, 6.40522655e-03, 2.56092568e-06],\n",
       "       [1.40853146e-05, 6.86454313e-03, 2.21779154e-06],\n",
       "       [1.35714557e-05, 5.93118120e-03, 2.45966869e-06],\n",
       "       [1.13614695e-05, 8.26413251e-03, 1.42791424e-06],\n",
       "       [1.41912679e-05, 5.93055211e-03, 2.89973246e-06],\n",
       "       [1.03826199e-05, 6.21408111e-03, 1.51831774e-06],\n",
       "       [1.21312984e-05, 6.96426436e-03, 1.80146192e-06],\n",
       "       [1.23145620e-05, 7.02336448e-03, 1.82712530e-06],\n",
       "       [1.49142350e-05, 6.36938209e-03, 2.67630524e-06],\n",
       "       [1.40314921e-05, 6.45981360e-03, 2.52677972e-06],\n",
       "       [1.47523976e-05, 6.47323775e-03, 2.47967697e-06],\n",
       "       [1.40580262e-05, 6.74607373e-03, 2.28395851e-06],\n",
       "       [1.02801383e-05, 8.81760646e-03, 8.05850409e-07],\n",
       "       [9.81844558e-06, 8.46702542e-03, 7.86704338e-07],\n",
       "       [1.04767700e-05, 8.38301908e-03, 8.01432003e-07],\n",
       "       [9.50114265e-06, 6.64761040e-03, 7.16659967e-07],\n",
       "       [9.87852942e-06, 7.59172457e-03, 7.44529750e-07],\n",
       "       [1.03050048e-05, 8.38907242e-03, 7.94037375e-07],\n",
       "       [9.62019933e-06, 8.26542635e-03, 7.54482894e-07],\n",
       "       [1.01558594e-05, 8.30693276e-03, 9.11017897e-07],\n",
       "       [1.10371511e-05, 8.60914866e-03, 8.51113703e-07],\n",
       "       [8.64061946e-06, 7.44801908e-03, 7.13039357e-07],\n",
       "       [1.07992304e-05, 6.95648134e-03, 8.56433252e-07],\n",
       "       [9.25587276e-06, 7.96383666e-03, 7.50444887e-07],\n",
       "       [1.25122116e-05, 7.61778524e-03, 8.97469494e-07],\n",
       "       [1.03615430e-05, 8.15732036e-03, 7.84380446e-07],\n",
       "       [9.28149243e-06, 8.29869580e-03, 7.95426317e-07],\n",
       "       [9.81817802e-06, 8.58152250e-03, 7.80926817e-07],\n",
       "       [8.91028029e-06, 7.84721276e-03, 6.84075324e-07],\n",
       "       [1.17925773e-05, 9.35302018e-03, 9.59501967e-07],\n",
       "       [9.23590892e-06, 5.28682436e-03, 5.81487507e-07],\n",
       "       [1.09132944e-05, 8.29672249e-03, 8.83059471e-07],\n",
       "       [7.63747760e-06, 6.78483086e-03, 5.50246856e-07],\n",
       "       [9.85193532e-06, 8.26467487e-03, 7.95720095e-07],\n",
       "       [9.49289042e-06, 6.16784678e-03, 6.20751571e-07],\n",
       "       [1.18446769e-05, 8.95217294e-03, 8.97732947e-07],\n",
       "       [1.03395483e-05, 8.52890168e-03, 8.19622123e-07],\n",
       "       [9.95626870e-06, 8.42810648e-03, 7.86972831e-07],\n",
       "       [1.09763237e-05, 8.01068295e-03, 8.10120749e-07],\n",
       "       [9.13844471e-06, 7.16043799e-03, 6.64176850e-07],\n",
       "       [9.42101287e-06, 7.66771763e-03, 7.27075989e-07],\n",
       "       [1.02895200e-05, 8.60742752e-03, 8.53220055e-07],\n",
       "       [1.07562516e-05, 7.97466330e-03, 8.67391983e-07],\n",
       "       [1.11622781e-05, 8.35857622e-03, 9.10515103e-07],\n",
       "       [1.02485480e-05, 8.37803052e-03, 8.39655532e-07],\n",
       "       [8.14978921e-06, 6.17276502e-03, 5.21737544e-07],\n",
       "       [8.48785540e-06, 7.85862227e-03, 6.43652554e-07],\n",
       "       [9.39636707e-06, 8.42999420e-03, 7.52800909e-07],\n",
       "       [1.01028393e-05, 8.34453750e-03, 7.87706172e-07],\n",
       "       [1.10856849e-05, 6.69638152e-03, 7.58212952e-07],\n",
       "       [1.00520668e-05, 8.82158399e-03, 8.39683779e-07],\n",
       "       [9.60602939e-06, 7.37909917e-03, 7.61395788e-07],\n",
       "       [1.04693340e-05, 8.28634870e-03, 7.99842049e-07],\n",
       "       [1.03663245e-05, 8.45136704e-03, 8.08830640e-07],\n",
       "       [1.05093659e-05, 8.16304788e-03, 8.42722301e-07],\n",
       "       [1.02933245e-05, 8.00196017e-03, 8.95138621e-07],\n",
       "       [9.96693002e-06, 8.02274675e-03, 7.94333272e-07],\n",
       "       [1.07619841e-05, 9.34511232e-03, 8.93621944e-07],\n",
       "       [1.01899609e-05, 8.59939275e-03, 8.32759448e-07],\n",
       "       [1.04407324e-05, 8.55389987e-03, 8.34634940e-07],\n",
       "       [9.23597464e-06, 7.94122959e-03, 8.22532801e-07],\n",
       "       [1.00323544e-05, 8.30115848e-03, 8.19545387e-07],\n",
       "       [6.24879758e-06, 5.06917447e-03, 3.84744836e-07],\n",
       "       [6.39621277e-06, 5.04870392e-03, 4.06436172e-07],\n",
       "       [7.02133634e-06, 5.06478454e-03, 4.11415710e-07],\n",
       "       [7.61447387e-06, 5.89046060e-03, 4.51353062e-07],\n",
       "       [6.42405203e-06, 4.87163958e-03, 3.82009798e-07],\n",
       "       [7.83353991e-06, 4.92735426e-03, 3.95201122e-07],\n",
       "       [5.95744850e-06, 5.44365077e-03, 4.22584088e-07],\n",
       "       [9.00865892e-06, 5.70671497e-03, 4.71118058e-07],\n",
       "       [7.85616723e-06, 4.49852520e-03, 3.97893002e-07],\n",
       "       [6.15163325e-06, 5.11898000e-03, 3.79732863e-07],\n",
       "       [7.13757960e-06, 6.08241061e-03, 4.95110313e-07],\n",
       "       [6.93677706e-06, 4.96352174e-03, 4.22541031e-07],\n",
       "       [6.62329593e-06, 5.15971737e-03, 4.16193181e-07],\n",
       "       [5.83387748e-06, 4.27596584e-03, 3.69958054e-07],\n",
       "       [5.15092761e-06, 4.16621897e-03, 3.49385515e-07],\n",
       "       [5.77720081e-06, 4.97131873e-03, 3.77538250e-07],\n",
       "       [7.98481332e-06, 6.15444203e-03, 5.01840541e-07],\n",
       "       [8.20958125e-06, 6.39483313e-03, 4.81655326e-07],\n",
       "       [7.53076953e-06, 3.31735172e-03, 3.03655590e-07],\n",
       "       [8.44175346e-06, 4.73210073e-03, 4.72919075e-07],\n",
       "       [6.12934417e-06, 4.97476885e-03, 3.83167537e-07],\n",
       "       [5.92526884e-06, 5.03493094e-03, 3.97408880e-07],\n",
       "       [8.40852520e-06, 4.59090464e-03, 3.82618671e-07],\n",
       "       [7.40200361e-06, 5.56180412e-03, 4.93929636e-07],\n",
       "       [6.98180758e-06, 5.71431395e-03, 4.38660418e-07],\n",
       "       [9.33738108e-06, 6.78198940e-03, 5.77072387e-07],\n",
       "       [7.42139805e-06, 5.88483390e-03, 5.15062027e-07],\n",
       "       [7.54740407e-06, 6.29198885e-03, 5.28109074e-07],\n",
       "       [6.39592703e-06, 4.64019908e-03, 3.78525456e-07],\n",
       "       [1.09042844e-05, 7.34333237e-03, 6.96612048e-07],\n",
       "       [8.42174844e-06, 5.12617274e-03, 4.51509633e-07],\n",
       "       [9.88906861e-06, 7.61825317e-03, 6.60458293e-07],\n",
       "       [6.09321834e-06, 4.41619967e-03, 3.64473085e-07],\n",
       "       [9.75803874e-06, 7.15711759e-03, 6.62959373e-07],\n",
       "       [9.21162040e-06, 6.95159479e-03, 5.08967463e-07],\n",
       "       [6.54294426e-06, 4.64883242e-03, 3.73033942e-07],\n",
       "       [5.97147410e-06, 5.13088362e-03, 3.80709790e-07],\n",
       "       [7.98895307e-06, 6.43606807e-03, 5.06805529e-07],\n",
       "       [7.43834265e-06, 6.29863543e-03, 5.27451748e-07],\n",
       "       [6.80950285e-06, 5.54168715e-03, 4.47083922e-07],\n",
       "       [5.65819617e-06, 4.57379148e-03, 3.55513672e-07],\n",
       "       [5.84870036e-06, 5.22984556e-03, 3.93879118e-07],\n",
       "       [6.39621277e-06, 5.04870392e-03, 4.06436172e-07],\n",
       "       [6.33237132e-06, 4.95833495e-03, 3.82866147e-07],\n",
       "       [5.64079939e-06, 4.69502362e-03, 3.57415819e-07],\n",
       "       [5.60988858e-06, 4.76856265e-03, 3.64961098e-07],\n",
       "       [6.60569556e-06, 4.51096148e-03, 4.03171650e-07],\n",
       "       [6.81965312e-06, 5.52498543e-03, 4.50697321e-07],\n",
       "       [6.03590430e-06, 5.32586898e-03, 3.91113502e-07],\n",
       "       [7.22930538e-06, 6.19528646e-03, 4.78416958e-07]])"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = predict(X)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.409286154603345"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_crossentropy(y,y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f,x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=[\"multi_index\"],op_flags=[\"readwrite\"])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh = f(x)\n",
    "        x[idx] = tmp_val\n",
    "        fx = f(x)\n",
    "        grad[idx] = (fxh-fx)/h\n",
    "        it.iternext()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gradient_descent(x,t):\n",
    "#     y = predict(x)\n",
    "#     W_loss = lambda W: categorical_crossentropy(y,t)\n",
    "#     dW1 = numerical_gradient(W_loss,W1)\n",
    "#     db1 = numerical_gradient(W_loss,b1)\n",
    "#     dW2 = numerical_gradient(W_loss,W2)\n",
    "#     db2 = numerical_gradient(W_loss,b2)\n",
    "#     W1 -= dW1*lr\n",
    "#     b1 -= db1*lr\n",
    "#     W2 -= dW2*lr\n",
    "#     b2 -= db2*lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(4,50)\n",
    "b1 = np.zeros(50)\n",
    "W2 = np.random.randn(50,3)\n",
    "b2 = np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.080036621501369"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1 = np.dot(X,W1) + b1\n",
    "z1 = sigmoid(layer1)\n",
    "layer2 = np.dot(z1,W2) + b2\n",
    "out = softmax(layer2)\n",
    "lr = 1e-4\n",
    "W_loss = lambda W: categorical_crossentropy(y,out)\n",
    "dW1 = numerical_gradient(W_loss,W1)\n",
    "db1 = numerical_gradient(W_loss,b1)\n",
    "dW2 = numerical_gradient(W_loss,W2)\n",
    "db2 = numerical_gradient(W_loss,b2)\n",
    "W1 -= dW1*lr\n",
    "b1 -= db1*lr\n",
    "W2 -= dW2*lr\n",
    "b2 -= db2*lr\n",
    "categorical_crossentropy(y,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]])"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_13740\\3375627744.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.mean(-t*np.log(y))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = predict(X)\n",
    "categorical_crossentropy(y_hat,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.W1 = np.random.randn(4,50)\n",
    "        self.b1 = np.zeros(50)\n",
    "        self.W2 = np.random.randn(50,3)\n",
    "        self.b2 = np.zeros(3)\n",
    "        self.err = None\n",
    "        \n",
    "    def predict(self,x):\n",
    "        y = np.dot(x, self.W1) + self.b1\n",
    "        y = sigmoid(y)\n",
    "        y = np.dot(y, self.W2) + self.b2\n",
    "        y = softmax(y)\n",
    "        return y\n",
    "        # return np.argmax(y, axis=1)\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        err = categorical_crossentropy(t,y)\n",
    "        self.err = err\n",
    "        return self.err\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y,axis=1)\n",
    "        t = np.argmax(t,axis=1)\n",
    "        acc = np.sum(y==t)/t.size\n",
    "        return acc\n",
    "    \n",
    "    def gradient(self,x,t):\n",
    "        # self.loss(x,t)\n",
    "        lr = 1e-4\n",
    "        W_loss = lambda W : self.loss(x,t)\n",
    "        dW1 = numerical_gradient(W_loss,self.W1)\n",
    "        db1 = numerical_gradient(W_loss,self.b1)\n",
    "        dW2 = numerical_gradient(W_loss,self.W2)\n",
    "        db2 = numerical_gradient(W_loss,self.b2)\n",
    "        self.W1 -= dW1*lr\n",
    "        self.b1 -= db1*lr\n",
    "        self.W2 -= dW2*lr\n",
    "        self.b2 -= db2*lr\n",
    "        return self.err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99648698e-01, 3.42113802e-04, 9.18827257e-06]])"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6580091652471114"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6580091652471114"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.gradient(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6577326456271577\n"
     ]
    }
   ],
   "source": [
    "# epochs = 10000\n",
    "# for epoch in range(epochs):\n",
    "#     model.gradient(X,y)\n",
    "#     if epoch % 100 == 0:\n",
    "#         print(model.err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 3.6301139564151543 === accuracy : 0.3333333333333333\n",
      "loss : 3.603351746922548 === accuracy : 0.3333333333333333\n",
      "loss : 3.5771378522477475 === accuracy : 0.3333333333333333\n",
      "loss : 3.551440901574507 === accuracy : 0.3333333333333333\n",
      "loss : 3.526230304722645 === accuracy : 0.3333333333333333\n",
      "loss : 3.5014765879919882 === accuracy : 0.3333333333333333\n",
      "loss : 3.4771516367446584 === accuracy : 0.3333333333333333\n",
      "loss : 3.453228860217893 === accuracy : 0.3333333333333333\n",
      "loss : 3.429683292889241 === accuracy : 0.3333333333333333\n",
      "loss : 3.4064916451245724 === accuracy : 0.3333333333333333\n",
      "loss : 3.383632314089135 === accuracy : 0.3333333333333333\n",
      "loss : 3.3610853641661547 === accuracy : 0.3333333333333333\n",
      "loss : 3.3388324845141444 === accuracy : 0.3333333333333333\n",
      "loss : 3.3168569299585497 === accuracy : 0.3333333333333333\n",
      "loss : 3.295143450178737 === accuracy : 0.3333333333333333\n",
      "loss : 3.2736782111169163 === accuracy : 0.3333333333333333\n",
      "loss : 3.2524487116873533 === accuracy : 0.3333333333333333\n",
      "loss : 3.23144369818137 === accuracy : 0.3333333333333333\n",
      "loss : 3.210653078222018 === accuracy : 0.3333333333333333\n",
      "loss : 3.1900678356976067 === accuracy : 0.3333333333333333\n",
      "loss : 3.1696799477730697 === accuracy : 0.3333333333333333\n",
      "loss : 3.1494823048216314 === accuracy : 0.3333333333333333\n",
      "loss : 3.1294686339199393 === accuracy : 0.3333333333333333\n",
      "loss : 3.1096334263918277 === accuracy : 0.3333333333333333\n",
      "loss : 3.089971869759265 === accuracy : 0.3333333333333333\n",
      "loss : 3.0704797843533105 === accuracy : 0.3333333333333333\n",
      "loss : 3.051153564747879 === accuracy : 0.3333333333333333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\StudyPython_Deep_Learning\\4day\\01_study_4day.ipynb 셀 33\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model\u001b[39m.\u001b[39;49mgradient(X,y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss : \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39merr\u001b[39m}\u001b[39;00m\u001b[39m === accuracy : \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39maccuracy(X,y)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\StudyPython_Deep_Learning\\4day\\01_study_4day.ipynb 셀 33\u001b[0m in \u001b[0;36mNetwork.gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m dW1 \u001b[39m=\u001b[39m numerical_gradient(W_loss,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m db1 \u001b[39m=\u001b[39m numerical_gradient(W_loss,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb1)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m dW2 \u001b[39m=\u001b[39m numerical_gradient(W_loss,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m db2 \u001b[39m=\u001b[39m numerical_gradient(W_loss,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW1 \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m dW1\u001b[39m*\u001b[39mlr\n",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\StudyPython_Deep_Learning\\4day\\01_study_4day.ipynb 셀 33\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m tmp_val \u001b[39m=\u001b[39m x[idx]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m x[idx] \u001b[39m=\u001b[39m tmp_val \u001b[39m+\u001b[39m h\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m fxh \u001b[39m=\u001b[39m f(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m x[idx] \u001b[39m=\u001b[39m tmp_val\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m fx \u001b[39m=\u001b[39m f(x)\n",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\StudyPython_Deep_Learning\\4day\\01_study_4day.ipynb 셀 33\u001b[0m in \u001b[0;36mNetwork.gradient.<locals>.<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgradient\u001b[39m(\u001b[39mself\u001b[39m,x,t):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# self.loss(x,t)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     lr \u001b[39m=\u001b[39m \u001b[39m1e-4\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     W_loss \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m W : \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(x,t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     dW1 \u001b[39m=\u001b[39m numerical_gradient(W_loss,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     db1 \u001b[39m=\u001b[39m numerical_gradient(W_loss,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb1)\n",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\StudyPython_Deep_Learning\\4day\\01_study_4day.ipynb 셀 33\u001b[0m in \u001b[0;36mNetwork.loss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m,x,t):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     err \u001b[39m=\u001b[39m categorical_crossentropy(t,y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merr \u001b[39m=\u001b[39m err\n",
      "\u001b[1;32mc:\\Users\\admin\\STUDY\\StudyPython_Deep_Learning\\4day\\01_study_4day.ipynb 셀 33\u001b[0m in \u001b[0;36mNetwork.predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW1) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     y \u001b[39m=\u001b[39m sigmoid(y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/STUDY/StudyPython_Deep_Learning/4day/01_study_4day.ipynb#X44sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW2) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb2\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    model.gradient(X,y)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'loss : {model.err} === accuracy : {model.accuracy(X,y)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_kernel",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38ae1ba9371524da054e8e3fbefd778d16b5a8ac7937a3f395010f627bb73919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
