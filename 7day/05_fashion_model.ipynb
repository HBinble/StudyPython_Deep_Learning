{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기본 모듈\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## 모듈 import\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_dict = {0 : \"T-shirt/top\",\n",
    "1 : \"Trouser\",\n",
    "2 : \"Pullover\",\n",
    "3 : \"Dress\",\n",
    "4 : \"Coat\",\n",
    "5 : \"Sandal\",\n",
    "6 : \"Shirt\",\n",
    "7 : \"Sneaker\",\n",
    "8 : \"Bag\",\n",
    "9 : \"Ankel boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dress\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])\n",
    "print(fashion_dict[y_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 28, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_train --> Flatten --> Dense --> Dense --> Dense --> Dense(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "output_shape = y_train.shape[1]\n",
    "\n",
    "model1 = Sequential(\n",
    "    [\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(2048,activation=\"relu\"),\n",
    "        Dense(1024,activation=\"relu\"),\n",
    "        Dense(512,activation=\"relu\"),\n",
    "        Dense(output_shape,activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model2 = Sequential(\n",
    "    [\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(2048,activation=\"sigmoid\"),\n",
    "        Dense(1024,activation=\"sigmoid\"),\n",
    "        Dense(512,activation=\"sigmoid\"),\n",
    "        Dense(output_shape,activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,len(model1.layers)):\n",
    "    model2.layers[i].set_weights([model1.layers[i].get_weights()[0],\n",
    "                                model1.layers[i].get_weights()[1]])\n",
    "np.sum(model1.layers[1].get_weights()[0]) == np.sum(model2.layers[1].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18145dbd450>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = \"adam\"\n",
    "loss = \"categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model1.compile(optimizer=optimizer,\n",
    "            loss =loss,\n",
    "            metrics=metrics)\n",
    "model2.compile(optimizer=optimizer,\n",
    "            loss =loss,\n",
    "            metrics=metrics)\n",
    "\n",
    "model1.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=10,\n",
    "        batch_size=400,\n",
    "        verbose=0\n",
    "        )\n",
    "model2.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=10,\n",
    "        batch_size=400,\n",
    "        verbose=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3894 - accuracy: 0.8776\n",
      "relu [0.389365017414093, 0.8776000142097473]\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.5281 - accuracy: 0.8007\n",
      "sigmoid [0.5280756950378418, 0.8007000088691711]\n"
     ]
    }
   ],
   "source": [
    "print(\"relu\", model1.evaluate(X_test,y_test))\n",
    "print(\"sigmoid\", model2.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 분포 값 변경 (relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "output_shape = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential(\n",
    "    [\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(1024,activation=\"relu\"),\n",
    "        Dense(512,activation=\"relu\"),\n",
    "        Dense(256,activation=\"relu\"),\n",
    "        Dense(output_shape,activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model2 = Sequential(\n",
    "    [\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(2048,activation=\"relu\"),\n",
    "        Dense(1024,activation=\"relu\"),\n",
    "        Dense(512,activation=\"relu\"),\n",
    "        Dense(output_shape,activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1814bdef760>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = \"adam\"\n",
    "loss = \"categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model1.compile(optimizer=optimizer,\n",
    "            loss =loss,\n",
    "            metrics=metrics)\n",
    "model2.compile(optimizer=optimizer,\n",
    "            loss =loss,\n",
    "            metrics=metrics)\n",
    "\n",
    "model1.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=10,\n",
    "        batch_size=400,\n",
    "        verbose=0\n",
    "        )\n",
    "model2.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=10,\n",
    "        batch_size=400,\n",
    "        verbose=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4655 - accuracy: 0.8549\n",
      "relu1 [0.4655281603336334, 0.8549000024795532]\n",
      "313/313 [==============================] - 3s 7ms/step - loss: 0.3615 - accuracy: 0.8766\n",
      "relu2 [0.3614659011363983, 0.8766000270843506]\n"
     ]
    }
   ],
   "source": [
    "print(\"relu1\", model1.evaluate(X_test,y_test))\n",
    "print(\"relu2\", model2.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### optimizer = \"rmsprop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential(\n",
    "    [\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(2048,activation=\"relu\"),\n",
    "        Dense(1024,activation=\"relu\"),\n",
    "        Dense(512,activation=\"relu\"),\n",
    "        Dense(output_shape,activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model2 = Sequential(\n",
    "    [\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(2048,activation=\"relu\"),\n",
    "        Dense(1024,activation=\"relu\"),\n",
    "        Dense(512,activation=\"relu\"),\n",
    "        Dense(256,activation=\"relu\"),\n",
    "        Dense(128,activation=\"relu\"),\n",
    "        Dense(output_shape,activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18147b37430>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = \"rmsprop\"\n",
    "loss = \"categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model1.compile(optimizer=optimizer,\n",
    "            loss =loss,\n",
    "            metrics=metrics)\n",
    "model2.compile(optimizer=optimizer,\n",
    "            loss =loss,\n",
    "            metrics=metrics)\n",
    "\n",
    "model1.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=10,\n",
    "        batch_size=400,\n",
    "        verbose=0\n",
    "        )\n",
    "model2.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=10,\n",
    "        batch_size=400,\n",
    "        verbose=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4523 - accuracy: 0.8490\n",
      "rmsprop short [0.4523293077945709, 0.8489999771118164]\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4532 - accuracy: 0.8558\n",
      "rmsprop long [0.4532102048397064, 0.8557999730110168]\n"
     ]
    }
   ],
   "source": [
    "print(\"rmsprop short\", model1.evaluate(X_test,y_test))\n",
    "print(\"rmsprop long\", model2.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Flatten(input_shape=input_shape))\n",
    "model1.add(Dense(1024,activation=\"relu\"))\n",
    "model1.add(Dense(512,activation=\"relu\"))\n",
    "model1.add(Dense(256,activation=\"relu\"))\n",
    "model1.add(Dense(output_shape,activation=\"softmax\"))\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=input_shape))\n",
    "model2.add(Dense(1024,activation=\"relu\"))\n",
    "model2.add(Dense(512,activation=\"relu\"))\n",
    "model2.add(Dense(256,activation=\"relu\"))\n",
    "model2.add(Dense(output_shape,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = \"adam\"\n",
    "loss = \"categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model1.compile(optimizer=optimizer,\n",
    "            loss =loss,\n",
    "            metrics=metrics)\n",
    "model2.compile(optimizer=optimizer,\n",
    "            loss =loss,\n",
    "            metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 6.5948 - accuracy: 0.6668\n",
      "adam1 [6.594831943511963, 0.6668000221252441]\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.4306 - accuracy: 0.8689\n",
      "adam2 [0.4305586516857147, 0.8689000010490417]\n",
      "CPU times: total: 10min 38s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "model1.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=20,\n",
    "        batch_size=len(X_train),\n",
    "        verbose=0\n",
    "        )\n",
    "model2.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=20,\n",
    "        batch_size=400,\n",
    "        verbose=0\n",
    "        )\n",
    "\n",
    "print(\"adam1\", model1.evaluate(X_test,y_test))\n",
    "print(\"adam2\", model2.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 0.7744 - accuracy: 0.8196\n",
      "adam1 [0.7743507623672485, 0.819599986076355]\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6334 - accuracy: 0.8821\n",
      "adam2 [0.6333572864532471, 0.882099986076355]\n",
      "\n",
      "\n",
      "0:00:53.044490 \n",
      "\n",
      "0:01:37.790548\n"
     ]
    }
   ],
   "source": [
    "model1_s = datetime.now()\n",
    "model1.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=30,\n",
    "        batch_size=len(X_train),\n",
    "        verbose=0\n",
    "        )\n",
    "model1_e = datetime.now()\n",
    "model1_t = model1_e - model1_s\n",
    "\n",
    "model2_s = datetime.now()\n",
    "model2.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=30,\n",
    "        batch_size=400,\n",
    "        verbose=0\n",
    "        )\n",
    "model2_e = datetime.now()\n",
    "model2_t = model2_e - model2_s\n",
    "\n",
    "\n",
    "print(\"adam1\", model1.evaluate(X_test,y_test))\n",
    "print(\"adam2\", model2.evaluate(X_test,y_test))\n",
    "print(\"\\n\")\n",
    "print(model1_t, \"\\n\")\n",
    "print(model2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "313/313 [==============================] - 1s 4ms/step\n",
      "313/313 [==============================] - 2s 5ms/step\n",
      "313/313 [==============================] - 2s 5ms/step\n",
      "313/313 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': [45000, 22500, 11250, 5625, 2812],\n",
       " 'time': [datetime.timedelta(seconds=33, microseconds=909947),\n",
       "  datetime.timedelta(seconds=41, microseconds=268141),\n",
       "  datetime.timedelta(seconds=44, microseconds=543682),\n",
       "  datetime.timedelta(seconds=47, microseconds=124798),\n",
       "  datetime.timedelta(seconds=47, microseconds=239441)],\n",
       " 'accuracy': [0.6536, 0.7615, 0.7941, 0.829, 0.7438]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [Flatten(input_shape=input_shape),\n",
    "    Dense(1024,activation=\"relu\"),\n",
    "    Dense(512,activation=\"relu\"),\n",
    "    Dense(256,activation=\"relu\"),\n",
    "    Dense(output_shape,activation=\"softmax\")]\n",
    ")\n",
    "\n",
    "batch_size = [len(X_train), int(len(X_train)/2), int(len(X_train)/4),\n",
    "            int(len(X_train)/8), int(len(X_train)/16)]\n",
    "\n",
    "elapse_time = []\n",
    "accuracy = []\n",
    "l1 = [model.layers[1].get_weights()[0], model.layers[1].get_weights()[1]] \n",
    "l2 = [model.layers[2].get_weights()[0], model.layers[2].get_weights()[1]] \n",
    "l3 = [model.layers[3].get_weights()[0], model.layers[3].get_weights()[1]] \n",
    "l4 = [model.layers[4].get_weights()[0], model.layers[4].get_weights()[1]] \n",
    "\n",
    "for i in range(len(batch_size)):\n",
    "    model.layers[1].set_weights(l1)\n",
    "    model.layers[2].set_weights(l2)\n",
    "    model.layers[3].set_weights(l3)\n",
    "    model.layers[4].set_weights(l4)\n",
    "    \n",
    "    optimizer = \"adam\"\n",
    "    loss = \"categorical_crossentropy\"\n",
    "    metrics = [\"accuracy\"]\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "            loss =loss,\n",
    "            metrics=metrics)\n",
    "    \n",
    "    st_time = datetime.now()\n",
    "    model.fit(X_train, \n",
    "            y_train,\n",
    "            epochs=20,\n",
    "            batch_size = batch_size[i],\n",
    "            verbose=0)\n",
    "    ed_time = datetime.now()\n",
    "    elapse_time.append(ed_time - st_time)\n",
    "    \n",
    "    acc = np.sum(np.argmax(model.predict(X_test),axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    accuracy.append(acc)\n",
    "    \n",
    "result = {\"batch_size\":batch_size, \"time\":elapse_time, \"accuracy\":accuracy}\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>time</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45000</td>\n",
       "      <td>0 days 00:00:33.909947</td>\n",
       "      <td>0.6536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22500</td>\n",
       "      <td>0 days 00:00:41.268141</td>\n",
       "      <td>0.7615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>0 days 00:00:44.543682</td>\n",
       "      <td>0.7941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5625</td>\n",
       "      <td>0 days 00:00:47.124798</td>\n",
       "      <td>0.8290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2812</td>\n",
       "      <td>0 days 00:00:47.239441</td>\n",
       "      <td>0.7438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size                   time  accuracy\n",
       "0       45000 0 days 00:00:33.909947    0.6536\n",
       "1       22500 0 days 00:00:41.268141    0.7615\n",
       "2       11250 0 days 00:00:44.543682    0.7941\n",
       "3        5625 0 days 00:00:47.124798    0.8290\n",
       "4        2812 0 days 00:00:47.239441    0.7438"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[1].set_weights(l1)\n",
    "# model.layers[2].set_weights(l2)\n",
    "# model.layers[3].set_weights(l3)\n",
    "# model.layers[4].set_weights(l4)\n",
    "\n",
    "# optimizer = \"adam\"\n",
    "# loss = \"categorical_crossentropy\"\n",
    "# metrics = [\"accuracy\"]\n",
    "\n",
    "# model.compile(optimizer=optimizer,\n",
    "#         loss =loss,\n",
    "#         metrics=metrics)\n",
    "\n",
    "# st_time = datetime.now()\n",
    "# model.fit(X_train, \n",
    "#         y_train,\n",
    "#         epochs=20,\n",
    "#         batch_size = 1,\n",
    "#         verbose=0)\n",
    "# ed_time = datetime.now()\n",
    "# elapse = ed_time - st_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "output_shape = y_train.shape[1]\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Flatten(input_shape=input_shape),\n",
    "        Dense(1024,activation=\"relu\"),\n",
    "        Dense(512,activation=\"relu\"),\n",
    "        Dense(256,activation=\"relu\"),\n",
    "        Dense(128,activation=\"relu\"),\n",
    "        Dense(output_shape,activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = \"adam\"\n",
    "loss = \"categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "            loss =loss,\n",
    "            metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,\n",
    "        y_train,\n",
    "        epochs=30,\n",
    "        validation_data=(X_val,y_val),\n",
    "        batch_size=1000\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### history.history(overfitting 판단시 사용) - dict 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,31),model.history.history[\"loss\"])\n",
    "plt.plot(np.arange(1,31),model.history.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,31),model.history.history[\"accuracy\"])\n",
    "plt.plot(np.arange(1,31),model.history.history[\"val_accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras1",
   "language": "python",
   "name": "keras1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
